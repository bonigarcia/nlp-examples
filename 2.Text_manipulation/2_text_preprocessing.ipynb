{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_text_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQ0SJH6rMB_"
      },
      "source": [
        "**NLTK setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SktJzo4zrKkg"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1XUz3f4F9-4"
      },
      "source": [
        "**Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjUz7ar8l1Ez",
        "outputId": "10e2f3ff-f972-44b7-c0d7-4c500ff70fb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "my_message = \"@Everybody: Hello NLP-world!\"\n",
        "word_tokenize(my_message)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@', 'Everybody', ':', 'Hello', 'NLP-world', '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "693oQ6X1nUFX",
        "outputId": "405171dc-2571-4bc0-d846-fa427a1237bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "\n",
        "wordpunct_tokenize(my_message)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@', 'Everybody', ':', 'Hello', 'NLP', '-', 'world', '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxS7HjZun4kh",
        "outputId": "b10925d5-829d-4ce7-9614-7f12840609dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import regexp_tokenize\n",
        "\n",
        "regexp_tokenize(my_message, \"\\w+|[!,\\-,]\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Everybody', 'Hello', 'NLP', '-', 'world', '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmUC3n1rpbAZ"
      },
      "source": [
        "**Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YE64x4spih6",
        "outputId": "272da1e5-c8cc-4ecc-d928-09ed19ad59d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemming = PorterStemmer()\n",
        "\n",
        "print(stemming.stem(\"enjoying\"))\n",
        "print(stemming.stem(\"enjoys\"))\n",
        "print(stemming.stem(\"enjoyable\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enjoy\n",
            "enjoy\n",
            "enjoy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSjbRREXq0fW"
      },
      "source": [
        "**Removing stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju-QZPcYq205",
        "outputId": "62a316a9-2502-4dde-889a-d87ef9d1cfd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "stopwords_en = stopwords.words('english')\n",
        "print(\"Count of stop word in English:\", len(stopwords_en))\n",
        "print(\"Stop words from position 20 to 30:\", stopwords_en[20:30])\n",
        "\n",
        "example_text = \"This is an example sentence to test stopwords\"\n",
        "example_text_without_stopwords = [word for word in example_text.split() if word not in stopwords_en]\n",
        "print(example_text)\n",
        "print(example_text_without_stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Count of stop word in English: 179\n",
            "Stop words from position 20 to 30: ['himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself']\n",
            "This is an example sentence to test stopwords\n",
            "['This', 'example', 'sentence', 'test', 'stopwords']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5dCifvIsHBv",
        "outputId": "33b682af-0239-4c07-e1b5-cf4eba7166b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import gutenberg\n",
        "nltk.download(\"gutenberg\")\n",
        "\n",
        "words_in_hamlet = gutenberg.words(\"shakespeare-hamlet.txt\")\n",
        "words_in_hamlet_without_sw = [word for word in words_in_hamlet if word not in stopwords_en]\n",
        "\n",
        "sw_percentage = len(words_in_hamlet_without_sw) * 100 / len(words_in_hamlet)\n",
        "print(\"The percentage of stopwords in Hamlet is\", sw_percentage, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "The percentage of stopwords in Hamlet is 69.26124197002142 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}